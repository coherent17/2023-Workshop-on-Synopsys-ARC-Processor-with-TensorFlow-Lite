{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concrete-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-reducing",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "another-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\mnb51\\tensorflow_datasets\\emnist\\digits\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115ef49705cf47878a0ea20f8aa3d3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9993dd48d44a909acf12bf00e6c650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095f962c43fd4711a5de072b78a74491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011e6d1c16144f33bcd1fb4e0283e49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\mnb51\\tensorflow_datasets\\emnist\\digits\\3.0.0.incompleteIVEZQ4\\emnist-train.tfrecord*...:  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\mnb51\\tensorflow_datasets\\emnist\\digits\\3.0.0.incompleteIVEZQ4\\emnist-test.tfrecord*...:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset emnist downloaded and prepared to C:\\Users\\mnb51\\tensorflow_datasets\\emnist\\digits\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import training and testing dataset and save to the dataset_buffer\n",
    "\n",
    "train_images_database, train_labels_database = tfds.as_numpy(tfds.load(\n",
    "    'emnist/digits',\n",
    "    split = 'train',\n",
    "    shuffle_files = False,\n",
    "    batch_size = -1,\n",
    "    as_supervised = True,\n",
    "))\n",
    "\n",
    "test_images_database, test_labels_database = tfds.as_numpy(tfds.load(\n",
    "    'emnist/digits',\n",
    "    split = 'test',\n",
    "    shuffle_files = False,\n",
    "    batch_size = -1,\n",
    "    as_supervised = True,\n",
    "))\n",
    "\n",
    "# plt.figure(1)\n",
    "# img = train_images_database[2, :, :, :]\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# Transport row/col of image\n",
    "for img_index in range(0, train_images_database.shape[0]):\n",
    "    for channel_index in range(0, train_images_database.shape[3]):\n",
    "        train_images_database[img_index, :, :, channel_index] =  train_images_database[img_index, :, :, channel_index].transpose()\n",
    "        \n",
    "# Transport row/col of image\n",
    "for img_index in range(0, test_images_database.shape[0]):\n",
    "    for channel_index in range(0, test_images_database.shape[3]):\n",
    "        test_images_database[img_index, :, :, channel_index] =  test_images_database[img_index, :, :, channel_index].transpose()\n",
    "\n",
    "# plt.figure(2)\n",
    "# img = train_images_database[2, :, :, :]\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "                  \n",
    "num_classes = np.amax(train_labels_database);\n",
    "total_train_image = train_images_database.shape[0];\n",
    "total_test_image = test_images_database.shape[0];\n",
    "\n",
    "# Make class numbering start at 0\n",
    "train_labels_database = train_labels_database - 1\n",
    "test_labels_database = test_labels_database - 1\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "img_channel = 1\n",
    "input_shape = (img_rows, img_cols, img_channel)\n",
    "\n",
    "train_images_database = train_images_database.reshape([train_images_database.shape[0], img_rows, img_cols, img_channel])\n",
    "test_images_database = test_images_database.reshape([test_images_database.shape[0], img_rows, img_cols, img_channel])\n",
    "\n",
    "# print(train_images_database.shape[0])\n",
    "# print(test_images_database.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-object",
   "metadata": {},
   "source": [
    "## Load and process training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "train_images = train_images_database\n",
    "train_labels = train_labels_database\n",
    "\n",
    "test_images = test_images_database\n",
    "test_labels = test_labels_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qualified-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocessing #1\n",
    "\n",
    "# Transfer to nparray\n",
    "train_images = train_images.astype('float32')\n",
    "train_labels = to_categorical(train_labels, num_classes, dtype = 'float32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_labels = to_categorical(test_labels, num_classes, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocessing #2(continue)\n",
    "\n",
    "# Normalize\n",
    "def thinning(image):\n",
    "    tmp = np.where(image < 210.0, 0, image)\n",
    "    return np.where(image < 210.0, 0, 255)\n",
    "\n",
    "train_images = thinning(train_images)\n",
    "train_images = (train_images - 128.0) / 128.0\n",
    "\n",
    "test_images = thinning(test_images)\n",
    "test_images = (test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-edinburgh",
   "metadata": {},
   "source": [
    "## Model define and create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "israeli-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model create #1\n",
    "filter_x = 5;\n",
    "filter_y = 5;\n",
    "\n",
    "model=Sequential()\n",
    "#Conv1\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=(filter_x, filter_y), \n",
    "                 padding=\"same\",  \n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#Conv2\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(filter_x, filter_y), \n",
    "                 padding=\"same\", \n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#Conv3\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(filter_x, filter_y), \n",
    "                 padding=\"same\", \n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "committed-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model create #2(continue)\n",
    "\n",
    "#FC1\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#FC2\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "promising-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 585       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 58,537\n",
      "Trainable params: 58,249\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show your model\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-topic",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driving-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "960/960 [==============================] - 105s 110ms/step - loss: 0.0935 - accuracy: 0.9764 - val_loss: 0.0677 - val_accuracy: 0.9800\n",
      "Epoch 2/2\n",
      "960/960 [==============================] - 108s 113ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 0.0494 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df94a7b9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "#Define optimizer loss function and merics \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set training\n",
    "model.fit(train_images, train_labels,\n",
    "          validation_split = 0.2,\n",
    "          batch_size = 200,\n",
    "          verbose = 1,\n",
    "          epochs = 2\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abroad-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.05250454694032669\n",
      "accuracy 0.9833999872207642\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "score = model.evaluate(test_images, test_labels, verbose = 0)\n",
    "\n",
    "print('test loss', score[0])\n",
    "print('accuracy', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-tourism",
   "metadata": {},
   "source": [
    "#Save weights of this model  \n",
    "model.save_weights('my_model.h5')\n",
    "\n",
    "#load weights to this TensorFlow model  \n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "driven-postage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mnb51\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mnb51\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mnb51\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mnb51\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights of this model\n",
    "model.save('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equal-yield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.05250454694032669\n",
      "accuracy 0.9833999872207642\n"
     ]
    }
   ],
   "source": [
    "# lOAD model and weights of this model\n",
    "model_2 = keras.models.load_model('model_save')\n",
    "\n",
    "# Model Evaluation\n",
    "score = model_2.evaluate(test_images, test_labels, verbose = 0)\n",
    "print('test loss', score[0])\n",
    "print('accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "restricted-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-mechanism",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-copyright",
   "metadata": {},
   "source": [
    "## Reload and preprocess images in TFLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intellectual-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "test_images = test_images_database\n",
    "test_labels = test_labels_database\n",
    "\n",
    "def thinning(image):\n",
    "    return np.where(image < 210.0, 0, 255)\n",
    "\n",
    "test_images = thinning(test_images)\n",
    "test_images = (test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-silly",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Convert model into TFLM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coordinated-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incident-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.cast(test_images, tf.float32)\n",
    "tf_lite_ds = tf.data.Dataset.from_tensor_slices((test_images)).batch(1) #construct a dataset \n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tf_lite_ds.take(100):\n",
    "        yield [input_value]\n",
    "    \n",
    "converter.representative_dataset = representative_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "systematic-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mnb51\\AppData\\Local\\Temp\\tmpvnezp6vc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mnb51\\AppData\\Local\\Temp\\tmpvnezp6vc\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "converted_model = converter.convert()\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"emnist_model_int8.tflite\"\n",
    "converted_model_file.write_bytes(converted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-carrier",
   "metadata": {},
   "source": [
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-animation",
   "metadata": {},
   "source": [
    "## Evaluate TensorFlow Lite INT-8 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-choir",
   "metadata": {},
   "source": [
    "Full test set contains 14800 samples. Evaluating int8 model on it might take more than 10 minutes. \n",
    "If you want to get estimation faster, please, limit number of samples to be evaluated by reducing **max_samples** value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81a68486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "max_samples = int(test_images_database.shape[0] * 0.20)\n",
    "# max_samples = int(test_images_database.shape[0] * 1.00)\n",
    "\n",
    "print(max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "postal-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"emnist_model_int8.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    scale, zero_point = interpreter.get_output_details()[0]['quantization']\n",
    "\n",
    "    prediction_values = []\n",
    "    \n",
    "    for tflm_test_image in tflm_test_images[:max_samples]:\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\n",
    "        # the model's input data format.\n",
    "        tflm_test_image = np.expand_dims(tflm_test_image, axis=0) #.astype(np.float32)\n",
    "        tflm_test_image = np.int8(tflm_test_image / scale + zero_point)\n",
    "        interpreter.set_tensor(input_index, tflm_test_image)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Find the letter with highest probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        result = np.argmax(output()[0])\n",
    "        prediction_values.append(result)\n",
    "    \n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_values)):\n",
    "        if prediction_values[index] == ans_test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\n",
    "\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dominant-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "tflm_test_images = test_images_database\n",
    "ans_test_labels = test_labels_database\n",
    "\n",
    "def thinning(image):\n",
    "    return np.where(image < 210.0, 0, 255)\n",
    "\n",
    "tflm_test_images = thinning(tflm_test_images)\n",
    "tflm_test_images = (tflm_test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-inflation",
   "metadata": {},
   "source": [
    "Please, keep in mind that full test dataset evaluation on int8 model may take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-treasury",
   "metadata": {},
   "source": [
    "Evaluate the accuracy without normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incorporated-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "tflm_test_images = test_images_database\n",
    "ans_test_labels = test_labels_database\n",
    "\n",
    "tflm_test_images = (tflm_test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-construction",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-seventh",
   "metadata": {},
   "source": [
    "## Create a test set for target application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Import training and testing from dataset_buffer\n",
    "test_images = test_images_database\n",
    "test_labels = test_labels_database\n",
    "\n",
    "test_images = test_images.reshape([test_images.shape[0], img_rows, img_cols, img_channel])\n",
    "\n",
    "num_of_samples = 25\n",
    "random_test_images = random.sample(range(1, test_images.shape[0]), num_of_samples)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "rows = 5\n",
    "cols = 5\n",
    "\n",
    "for index in range(0, num_of_samples):\n",
    "    img = test_images[random_test_images[index]]\n",
    "    fig.add_subplot(rows, cols, (index + 1))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = open(\"generated/test_samples.cpp\", \"w\")\n",
    "\n",
    "samples_file.write(\"#include \\\"test_samples.h\\\"\\n\\n\")\n",
    "samples_file.write(\"const int kNumSamples = \" + str(num_of_samples) + \";\\n\\n\")\n",
    "\n",
    "samples = \"\" \n",
    "samples_array = \"const TestSample test_samples[kNumSamples] = {\"\n",
    "\n",
    "for sample_idx, img_idx in enumerate(random_test_images, 1):\n",
    "    img_arr = list(np.ndarray.flatten(test_images[img_idx]))\n",
    "    var_name = \"sample\" + str(sample_idx)\n",
    "    samples += \"TestSample \" + var_name + \" = {\\n\" #+ \"[IMAGE_SIZE] = { \"\n",
    "    samples += \"\\t.label = \" + str(test_labels[img_idx]) + \",\\n\" \n",
    "    samples += \"\\t.image = {\\n\"\n",
    "    wrapped_arr = [img_arr[i:i + 20] for i in range(0, len(img_arr), 20)]\n",
    "    for sub_arr in wrapped_arr:\n",
    "        samples += \"\\t\\t\" + str(sub_arr)\n",
    "    samples += \"\\t}\\n};\\n\\n\"    \n",
    "    samples_array += var_name + \", \"\n",
    "    \n",
    "samples = samples.replace(\"[\", \"\")\n",
    "samples = samples.replace(\"]\", \",\\n\")\n",
    "samples_array += \"};\\n\"\n",
    "\n",
    "samples_file.write(samples);\n",
    "samples_file.write(samples_array);\n",
    "samples_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-commonwealth",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-syria",
   "metadata": {},
   "source": [
    "You have converted a Tensorflow model into TFLM format and generated a test set for the application. Now you can copy generated files into target application of this tutorial and try it out:\n",
    "\n",
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application.\n",
    "\n",
    "* copy *generated/model.h* to *../inc* and *generated/test_samples.cpp* to *../src*\n",
    "* You can start to integrate your WE-I project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-flooring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
